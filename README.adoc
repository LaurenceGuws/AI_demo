= DeArx AI Chatbot for experimentation ğŸ¤–âœ¨

image::DeArx_chat\chat\static\icons\company-logo.png[Chatbot Demo Image]

Welcome to the future! This application aims to give us the oppertunity to explore LLM API's and open sourced models as a team!
Implementing an additional API into the app will be as simple as writing a class and adding it to the models folder (more details below). Were as hosting
a local model will still be added.''

== Features ğŸš€

* *Swap between configured models*
* *Swap between past conversations*
* *Add a model in a few simple steps*
* *Download your local db as csv files and more!*

== Getting Started ğŸ› 

=== Prerequisites

* Docker installed on your machine.
* Kubernetes cluster set up (local or cloud).
* Basic knowledge of Kubernetes.


=== Building the Docker Image

.First, navigate to the chat directory:
[source,bash]
----
cd .\DeArx_chat\chat
----

.Now, build the Docker image:
[source,bash]
----
docker build -t chat_py .
----

=== Deploying with Kubernetes

.Navigate to the Kubernetes directory:
[source,bash]
----
cd .\DeArx_chat\chat\k8s
----

.Apply the Kubernetes configurations:
[source,bash]
----
kubectl apply -f .
----

=== API Authentication

The necessary credentials will be:

* Added to `secret.yaml` as a base64 encoded string.
* Added to `deployment.yaml` under the `env:` tag.

.You can reference the credentials in Python as follows:
[source,python]
----
api_key = base64.b64decode(os.getenv('env_var_name_in_deployment_file')).decode()
----


== Contributing ğŸŒ

Feel free to submit issues, fork the repository and send pull requests!

To ensure your PR is considered, make sure you:

. Follow the coding standards.
. Write tests for the new code you've added.
. Document your changes in the README.

== License ğŸ“„

This project is licensed under the MIT License - see the link:LICENSE.adoc[LICENSE] file for details.

